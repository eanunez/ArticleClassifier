{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram MultiChannel Convolutional Neutral Network\n",
    " A class of N-Gram Multichannel Convolutional Neural Network which takes in Pandas' dataframe as an input data.\n",
    " This is an adaptation of Jason Brownlee's model which can be found at,\n",
    "\n",
    " https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/\n",
    "\n",
    " This approach was first described by Yoon Kim in his 2014 paper titled\n",
    " “Convolutional Neural Networks for Sentence Classification.”\n",
    "\n",
    " \"A multi-channel convolutional neural network for document classification\n",
    " involves using multiple versions of the standard model with different sized kernels.\n",
    " This allows the document to be processed at different resolutions or different\n",
    " n-grams (groups of words) at a time, whilst the model learns how to best integrate\n",
    " these interpretations.\" - Jason Brownlee, Ph.D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from multichan_cnn import MultiChanCnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Note: The datasets must be contained in csv file or dataframe with column names, 'input' and 'label'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/training_set.csv'\n",
    "df = pd.read_csv(path, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check information of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 427 entries, 0 to 426\n",
      "Data columns (total 2 columns):\n",
      "input    427 non-null object\n",
      "label    427 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Data\n",
    "Check the shape of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((283, 2), (144, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.loc[:, 'label'] == 'celebrity'].shape, df[df.loc[:, 'label'] == 'non-celeb'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sub-dataframe with balanced data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 288 entries, 3 to 426\n",
      "Data columns (total 2 columns):\n",
      "input    288 non-null object\n",
      "label    288 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sub_df = df[df.loc[:, 'label'] == 'celebrity'].head(144)\n",
    "sub_df = sub_df.append(df[df.loc[:, 'label'] == 'non-celeb'])\n",
    "sub_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((144, 2), (144, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[sub_df.loc[:, 'label'] == 'celebrity'].shape, sub_df[sub_df.loc[:, 'label'] == 'non-celeb'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Channel CNN\n",
    "Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = MultiChanCnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 1775\n",
      "Vocabulary size: 11673\n",
      "Train shape:  (217, 1775)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1775)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1775)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1775)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1775, 100)    1167300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1775, 100)    1167300     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1775, 100)    1167300     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1772, 32)     12832       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1770, 32)     19232       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1768, 32)     25632       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1772, 32)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1770, 32)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1768, 32)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 886, 32)      0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 885, 32)      0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 884, 32)      0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 28352)        0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 28320)        0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 28288)        0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 84960)        0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           849610      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            11          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,409,217\n",
      "Trainable params: 4,409,217\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "217/217 [==============================] - 8s 37ms/step - loss: 0.6833 - acc: 0.5346\n",
      "Epoch 2/10\n",
      "217/217 [==============================] - 7s 32ms/step - loss: 0.5925 - acc: 0.7097\n",
      "Epoch 3/10\n",
      "217/217 [==============================] - 7s 32ms/step - loss: 0.4431 - acc: 0.8157\n",
      "Epoch 4/10\n",
      "217/217 [==============================] - 7s 31ms/step - loss: 0.2403 - acc: 0.9816\n",
      "Epoch 5/10\n",
      "217/217 [==============================] - 7s 32ms/step - loss: 0.0784 - acc: 0.9954\n",
      "Epoch 6/10\n",
      "217/217 [==============================] - 7s 32ms/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.0017 - acc: 1.0000\n",
      "=== Evaluating Model ===\n",
      "Test shape:  (72, 1775)\n",
      "Test Accuracy: 84.722222\n"
     ]
    }
   ],
   "source": [
    "model = cnn.train(sub_df, save=True) # Set save=True if you want to save the model, Default: False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
