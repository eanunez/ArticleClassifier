{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram MultiChannel Convolutional Neutral Network\n",
    " A class of N-Gram Multichannel Convolutional Neural Network which takes in Pandas' dataframe as an input data.\n",
    " This is an adaptation of Jason Brownlee's model which can be found at,\n",
    "\n",
    " https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/\n",
    "\n",
    " This approach was first described by Yoon Kim in his 2014 paper titled\n",
    " “Convolutional Neural Networks for Sentence Classification.”\n",
    "\n",
    " \"A multi-channel convolutional neural network for document classification\n",
    " involves using multiple versions of the standard model with different sized kernels.\n",
    " This allows the document to be processed at different resolutions or different\n",
    " n-grams (groups of words) at a time, whilst the model learns how to best integrate\n",
    " these interpretations.\" - Jason Brownlee, Ph.D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from multichan_cnn import MultiChanCnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Note: The datasets must be contained in csv file or dataframe with column names, 'input' and 'label'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/training_set.csv'\n",
    "df = pd.read_csv(path, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check information of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 427 entries, 0 to 426\n",
      "Data columns (total 2 columns):\n",
      "input    427 non-null object\n",
      "label    427 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Data\n",
    "Check the shape of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((283, 2), (144, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.loc[:, 'label'] == 'celebrity'].shape, df[df.loc[:, 'label'] == 'non-celeb'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sub-dataframe with balanced data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 288 entries, 3 to 426\n",
      "Data columns (total 2 columns):\n",
      "input    288 non-null object\n",
      "label    288 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sub_df = df[df.loc[:, 'label'] == 'celebrity'].head(144)\n",
    "sub_df = sub_df.append(df[df.loc[:, 'label'] == 'non-celeb'])\n",
    "sub_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Channel CNN\n",
    "Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = MultiChanCnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 2145\n",
      "Vocabulary size: 8901\n",
      "Train shape:  (110, 2145)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2145)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2145)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 2145)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 2145, 100)    890100      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 2145, 100)    890100      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 2145, 100)    890100      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2142, 32)     12832       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2140, 32)     19232       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2138, 32)     25632       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2142, 32)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2140, 32)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2138, 32)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1071, 32)     0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1070, 32)     0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1069, 32)     0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 34272)        0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 34240)        0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 34208)        0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 102720)       0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           1027210     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            11          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,755,217\n",
      "Trainable params: 3,755,217\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.1035 - acc: 0.9636\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 4s 40ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 4s 39ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 4s 39ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 4s 38ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 4s 39ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 4s 38ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 4s 39ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 5s 41ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 4s 40ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "=== Evaluating Model ===\n",
      "Test shape:  (35, 2145)\n",
      "Test Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "model = cnn.train(sub_df, save=False) # Set save=True if you want to save the model, Default: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
