{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram MultiChannel Convolutional Neutral Network\n",
    " A class of N-Gram Multichannel Convolutional Neural Network which takes in Pandas' dataframe as an input data.\n",
    " This is an adaptation of Jason Brownlee's model which can be found at,\n",
    "\n",
    " https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/\n",
    "\n",
    " This approach was first described by Yoon Kim in his 2014 paper titled\n",
    " “Convolutional Neural Networks for Sentence Classification.”\n",
    "\n",
    " \"A multi-channel convolutional neural network for document classification\n",
    " involves using multiple versions of the standard model with different sized kernels.\n",
    " This allows the document to be processed at different resolutions or different\n",
    " n-grams (groups of words) at a time, whilst the model learns how to best integrate\n",
    " these interpretations.\" - Jason Brownlee, Ph.D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from multichan_cnn import MultiChanCnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Note: The datasets must be contained in csv file or dataframe with column names, 'input' and 'label'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/training_set.csv'\n",
    "df = pd.read_csv(path, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check information of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 427 entries, 0 to 426\n",
      "Data columns (total 2 columns):\n",
      "input    427 non-null object\n",
      "label    427 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Data\n",
    "Check the shape of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((283, 2), (144, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.loc[:, 'label'] == 'celebrity'].shape, df[df.loc[:, 'label'] == 'non-celeb'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sub-dataframe with balanced data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 288 entries, 3 to 426\n",
      "Data columns (total 2 columns):\n",
      "input    288 non-null object\n",
      "label    288 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sub_df = df[df.loc[:, 'label'] == 'celebrity'].head(144)\n",
    "sub_df = sub_df.append(df[df.loc[:, 'label'] == 'non-celeb'])\n",
    "sub_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((144, 2), (144, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[sub_df.loc[:, 'label'] == 'celebrity'].shape, sub_df[sub_df.loc[:, 'label'] == 'non-celeb'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Channel CNN\n",
    "Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = MultiChanCnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 2384\n",
      "Vocabulary size: 12479\n",
      "Train shape:  (217, 2384)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 2384)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 2384)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 2384)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 2384, 100)    1247900     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 2384, 100)    1247900     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 2384, 100)    1247900     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2381, 32)     12832       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 2379, 32)     19232       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 2377, 32)     25632       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2381, 32)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2379, 32)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 2377, 32)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1190, 32)     0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1189, 32)     0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 1188, 32)     0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 38080)        0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 38048)        0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 38016)        0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 114144)       0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           1141450     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            11          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,942,857\n",
      "Trainable params: 4,942,857\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "217/217 [==============================] - 11s 49ms/step - loss: 0.7094 - acc: 0.5300\n",
      "Epoch 2/10\n",
      "217/217 [==============================] - 9s 42ms/step - loss: 0.6605 - acc: 0.6129\n",
      "Epoch 3/10\n",
      "217/217 [==============================] - 9s 42ms/step - loss: 0.5894 - acc: 0.6912\n",
      "Epoch 4/10\n",
      "217/217 [==============================] - 9s 42ms/step - loss: 0.4925 - acc: 0.8111\n",
      "Epoch 5/10\n",
      "217/217 [==============================] - 9s 42ms/step - loss: 0.2744 - acc: 0.9677\n",
      "Epoch 6/10\n",
      "217/217 [==============================] - 9s 42ms/step - loss: 0.0707 - acc: 0.9862\n",
      "Epoch 7/10\n",
      "217/217 [==============================] - 9s 43ms/step - loss: 0.0181 - acc: 0.9954\n",
      "Epoch 8/10\n",
      "217/217 [==============================] - 10s 44ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "217/217 [==============================] - 9s 42ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "217/217 [==============================] - 9s 42ms/step - loss: 9.1547e-04 - acc: 1.0000\n",
      "=== Evaluating Model ===\n",
      "Test shape:  (72, 2384)\n",
      "Test Accuracy: 88.888889\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = cnn.train(sub_df, save=True) # Set save=True if you want to save the model, Default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "We can check the model prediction with actual article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_text = df[df.loc[:, 'label'] == 'celebrity'].loc[146, 'input']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tokenizer and encode the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "encoded = tokenizer.texts_to_sequences(unseen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences([unseen_vect], maxlen=2384, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18592758]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict([padded, padded, padded])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class = pred.argmax(axis=-1)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Keras has no mapping of classes to integer, we defined a mapping function in our Cnn class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'celebrity': 0, 'non-celeb': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.classes_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
