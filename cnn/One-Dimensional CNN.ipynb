{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Dimensional Convolutional Neutral Network\n",
    "\n",
    "This is to demonstrate a 1D CNN using Keras. The utility class accepts pandas dataframe as input for training and testing. \n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from one_dim_cnn import OneDimCnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "We use the data from BBC. The raw files can be downloaded here: http://mlg.ucd.ie/datasets/bbc.html.\n",
    "\n",
    "When we unzip the folder, bbc has subdirectories namely; business, entertainment, politics, sport and tech. We can use these folders as our target categories or labels. Each folder contains files belonged to the category.\n",
    "\n",
    "\n",
    "Note: README text file is removed for convinient parsing and contains.\n",
    "Consists of 2225 documents from the BBC news website corresponding to stories in five topical areas from 2004-2005.\n",
    "Natural Classes: 5 (business, entertainment, politics, sport, tech)\n",
    "\n",
    "If you make use of the dataset, please consider citing the publication: \n",
    "- D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006.\n",
    "\n",
    "All rights, including copyright, in the content of the original articles are owned by the BBC.\n",
    "\n",
    "Contact Derek Greene <derek.greene@ucd.ie> for further information.\n",
    "http://mlg.ucd.ie/datasets/bbc.html\n",
    "\n",
    "\n",
    "Note: The datasets must be contained in csv file or dataframe with column names, 'input' and 'label'. \n",
    "\n",
    "Let us check first if we have the desired list of folders in our path, 'bbc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list = os.listdir(os.path.abspath('data'))\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have the 5 lists of categories that later we will use as labels.\n",
    "Now, Let us define a function that scans all the contents for each category and list them all in pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(path):\n",
    "    \"\"\"Input contents to dataframe with corresponding label.\"\"\"\n",
    "    data = pd.DataFrame([], columns=['input', 'label'])\n",
    "    dir_list = os.listdir(os.path.abspath(path))\n",
    "    for folder in dir_list:\n",
    "        file_list = os.listdir(path + '/' + folder)\n",
    "        for f in file_list:\n",
    "            with open(path + '/'+ folder + '/' + f, 'r', newline='') as file:\n",
    "                data.loc[data['input'].shape[0] + 1,'input'] = file.read().strip()\n",
    "                data.loc[data['input'].shape[0], 'label'] = str(folder)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2225 entries, 1 to 2225\n",
      "Data columns (total 2 columns):\n",
      "input    2225 non-null object\n",
      "label    2225 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 132.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = loader('data')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input     label\n",
       "1  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "2  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "3  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "4  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "5  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above lines that there are 2225 entries which correspond to the number of documents. We also show the first 5 entries in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Data\n",
    "Check the shape of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:  business , shape:  (510, 2)\n",
      "category:  entertainment , shape:  (386, 2)\n",
      "category:  politics , shape:  (417, 2)\n",
      "category:  sport , shape:  (511, 2)\n",
      "category:  tech , shape:  (401, 2)\n"
     ]
    }
   ],
   "source": [
    "for lbl in df['label'].unique():\n",
    "    print('category: ', lbl, ', shape: ', df[df.loc[:, 'label'] == lbl].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the data having equal amounts, we will take the lowest number, 386."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame([])\n",
    "for lbl in df['label'].unique():\n",
    "    sub_df = sub_df.append(df[df.loc[:, 'label'] == lbl].head(386))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:  business , shape:  (386, 2)\n",
      "category:  entertainment , shape:  (386, 2)\n",
      "category:  politics , shape:  (386, 2)\n",
      "category:  sport , shape:  (386, 2)\n",
      "category:  tech , shape:  (386, 2)\n"
     ]
    }
   ],
   "source": [
    "for lbl in sub_df['label'].unique():\n",
    "    print('category: ', lbl, ', shape: ', sub_df[sub_df.loc[:, 'label'] == lbl].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a balanced data set, we can start training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Dimensional CNN\n",
    "Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 20, 'hidden_dims': 250, 'kernel_size': 3, 'filters': 250, 'embedding_dims': 100, 'batch_size': 32, 'maxlen': 2000, 'max_features': 50000, 'self': <one_dim_cnn.OneDimCnn object at 0x0000026220FD0160>}\n"
     ]
    }
   ],
   "source": [
    "cnn = OneDimCnn(max_features=50000, batch_size=32, embedding_dims=100, filters=250, maxlen=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train shape:  (1545, 2000)\n",
      "Test shape:  (386, 2000)\n",
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 2000, 100)         5000000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2000, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1998, 250)         75250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 5,139,255\n",
      "Trainable params: 5,139,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1545 samples, validate on 386 samples\n",
      "Epoch 1/20\n",
      "1545/1545 [==============================] - 55s 36ms/step - loss: 1.5513 - acc: 0.3379 - val_loss: 1.3136 - val_acc: 0.7150\n",
      "Epoch 2/20\n",
      "1545/1545 [==============================] - 54s 35ms/step - loss: 0.8520 - acc: 0.7864 - val_loss: 0.4233 - val_acc: 0.8886\n",
      "Epoch 3/20\n",
      "1545/1545 [==============================] - 52s 33ms/step - loss: 0.2817 - acc: 0.9301 - val_loss: 0.2348 - val_acc: 0.9249\n",
      "Epoch 4/20\n",
      "1545/1545 [==============================] - 54s 35ms/step - loss: 0.1217 - acc: 0.9683 - val_loss: 0.1231 - val_acc: 0.9585\n",
      "Epoch 5/20\n",
      "1545/1545 [==============================] - 50s 32ms/step - loss: 0.0584 - acc: 0.9890 - val_loss: 0.0887 - val_acc: 0.9663\n",
      "Epoch 6/20\n",
      "1545/1545 [==============================] - 54s 35ms/step - loss: 0.0258 - acc: 0.9922 - val_loss: 0.0812 - val_acc: 0.9819\n",
      "Epoch 7/20\n",
      "1545/1545 [==============================] - 56s 36ms/step - loss: 0.0086 - acc: 0.9987 - val_loss: 0.0777 - val_acc: 0.9689\n",
      "Epoch 8/20\n",
      "1545/1545 [==============================] - 56s 36ms/step - loss: 0.0042 - acc: 0.9994 - val_loss: 0.0670 - val_acc: 0.9741\n",
      "Epoch 9/20\n",
      "1545/1545 [==============================] - 56s 36ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 0.9767\n",
      "Epoch 10/20\n",
      "1545/1545 [==============================] - 52s 34ms/step - loss: 2.0882e-04 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 0.9767\n",
      "Epoch 11/20\n",
      "1545/1545 [==============================] - 53s 34ms/step - loss: 3.2128e-04 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 0.9715\n",
      "Epoch 12/20\n",
      "1545/1545 [==============================] - 54s 35ms/step - loss: 2.2702e-05 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9715\n",
      "Epoch 13/20\n",
      "1545/1545 [==============================] - 53s 35ms/step - loss: 5.0497e-05 - acc: 1.0000 - val_loss: 0.1022 - val_acc: 0.9767\n",
      "Epoch 14/20\n",
      "1545/1545 [==============================] - 53s 34ms/step - loss: 1.5668e-05 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9741\n",
      "Epoch 15/20\n",
      "1545/1545 [==============================] - 51s 33ms/step - loss: 2.0855e-06 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9715\n",
      "Epoch 16/20\n",
      "1545/1545 [==============================] - 50s 33ms/step - loss: 1.0689e-06 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9689\n",
      "Epoch 17/20\n",
      "1545/1545 [==============================] - 53s 34ms/step - loss: 3.5910e-07 - acc: 1.0000 - val_loss: 0.1083 - val_acc: 0.9689\n",
      "Epoch 18/20\n",
      "1545/1545 [==============================] - 55s 35ms/step - loss: 4.1037e-07 - acc: 1.0000 - val_loss: 0.1087 - val_acc: 0.9715\n",
      "Epoch 19/20\n",
      "1545/1545 [==============================] - 51s 33ms/step - loss: 3.0563e-07 - acc: 1.0000 - val_loss: 0.1039 - val_acc: 0.9767\n",
      "Epoch 20/20\n",
      "1545/1545 [==============================] - 55s 35ms/step - loss: 3.2335e-07 - acc: 1.0000 - val_loss: 0.1259 - val_acc: 0.9715\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = cnn.train(sub_df, save=False) # Set save=True if you want to save the model, Default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find from the above example that the validated accuracy in ~97%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "A sample content from BBC News is pulled out for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'business'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "text = 'Elon Musk unveils first tourist for SpaceX Moon loop. Japanese billionaire and online fashion tycoon Yusaku Maezawa, 42, announced: \"I choose to go to the Moon\".'\n",
    "vect_text = tokenizer.texts_to_sequences(text)\n",
    "padded = pad_sequences(vect_text, maxlen=2000, padding='post')\n",
    "pred = cnn.predict_class(model, padded)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
